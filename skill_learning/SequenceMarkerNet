digraph {
	graph [size="15.899999999999999,15.899999999999999"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140579476044272 [label="
 (1, 1, 7)" fillcolor=darkolivegreen1]
	140583302297776 [label=ViewBackward0]
	140583302297872 -> 140583302297776
	140583302297872 [label=AddmmBackward0]
	140583302297680 -> 140583302297872
	140579476042752 [label="fc_layers.2.bias
 (7)" fillcolor=lightblue]
	140579476042752 -> 140583302297680
	140583302297680 [label=AccumulateGrad]
	140583302297584 -> 140583302297872
	140583302297584 [label=ViewBackward0]
	140583302298016 -> 140583302297584
	140583302298016 [label=ReluBackward0]
	140583302298208 -> 140583302298016
	140583302298208 [label=ViewBackward0]
	140583302298832 -> 140583302298208
	140583302298832 [label=AddmmBackward0]
	140583302298928 -> 140583302298832
	140579476042592 [label="fc_layers.0.bias
 (32)" fillcolor=lightblue]
	140579476042592 -> 140583302298928
	140583302298928 [label=AccumulateGrad]
	140583302298784 -> 140583302298832
	140583302298784 [label=ViewBackward0]
	140583302298976 -> 140583302298784
	140583302298976 [label=TransposeBackward0]
	140583302299168 -> 140583302298976
	140583302299168 [label=MkldnnRnnLayerBackward0]
	140583302298880 -> 140583302299168
	140583302298880 [label=TransposeBackward0]
	140583302327360 -> 140583302298880
	140583302327360 [label=CatBackward0]
	140583302327744 -> 140583302327360
	140583302327744 [label=ViewBackward0]
	140583302328128 -> 140583302327744
	140583302328128 [label=MaxPool2DWithIndicesBackward0]
	140583302326976 -> 140583302328128
	140583302326976 [label=ReluBackward0]
	140583301833344 -> 140583302326976
	140583301833344 [label=ConvolutionBackward0]
	140583301833728 -> 140583301833344
	140583301833728 [label=MaxPool2DWithIndicesBackward0]
	140583301834160 -> 140583301833728
	140583301834160 [label=ReluBackward0]
	140579488081184 -> 140583301834160
	140579488081184 [label=ConvolutionBackward0]
	140583301861440 -> 140579488081184
	140583301861440 [label=MaxPool2DWithIndicesBackward0]
	140579476475568 -> 140583301861440
	140579476475568 [label=ReluBackward0]
	140579476475664 -> 140579476475568
	140579476475664 [label=ConvolutionBackward0]
	140579476475760 -> 140579476475664
	140579476008608 [label="cnn_layers.0.weight
 (32, 3, 3, 3)" fillcolor=lightblue]
	140579476008608 -> 140579476475760
	140579476475760 [label=AccumulateGrad]
	140579476475712 -> 140579476475664
	140579476008688 [label="cnn_layers.0.bias
 (32)" fillcolor=lightblue]
	140579476008688 -> 140579476475712
	140579476475712 [label=AccumulateGrad]
	140579476475376 -> 140579488081184
	140579476008848 [label="cnn_layers.3.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140579476008848 -> 140579476475376
	140579476475376 [label=AccumulateGrad]
	140579476475328 -> 140579488081184
	140579476041792 [label="cnn_layers.3.bias
 (64)" fillcolor=lightblue]
	140579476041792 -> 140579476475328
	140579476475328 [label=AccumulateGrad]
	140583301833536 -> 140583301833344
	140579476041952 [label="cnn_layers.6.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	140579476041952 -> 140583301833536
	140583301833536 [label=AccumulateGrad]
	140583301832768 -> 140583301833344
	140579476042032 [label="cnn_layers.6.bias
 (128)" fillcolor=lightblue]
	140579476042032 -> 140583301832768
	140583301832768 [label=AccumulateGrad]
	140583302299456 -> 140583302299168
	140579513804656 [label="lstm.weight_ih_l0
 (256, 100360)" fillcolor=lightblue]
	140579513804656 -> 140583302299456
	140583302299456 [label=AccumulateGrad]
	140583302299072 -> 140583302299168
	140579485803840 [label="lstm.weight_hh_l0
 (256, 64)" fillcolor=lightblue]
	140579485803840 -> 140583302299072
	140583302299072 [label=AccumulateGrad]
	140583302326400 -> 140583302299168
	140579476041872 [label="lstm.bias_ih_l0
 (256)" fillcolor=lightblue]
	140579476041872 -> 140583302326400
	140583302326400 [label=AccumulateGrad]
	140583302326592 -> 140583302299168
	140579476042112 [label="lstm.bias_hh_l0
 (256)" fillcolor=lightblue]
	140579476042112 -> 140583302326592
	140583302326592 [label=AccumulateGrad]
	140583302298112 -> 140583302298832
	140583302298112 [label=TBackward0]
	140583302299216 -> 140583302298112
	140579476042512 [label="fc_layers.0.weight
 (32, 64)" fillcolor=lightblue]
	140579476042512 -> 140583302299216
	140583302299216 [label=AccumulateGrad]
	140583302297824 -> 140583302297872
	140583302297824 [label=TBackward0]
	140583302298160 -> 140583302297824
	140579476042672 [label="fc_layers.2.weight
 (7, 32)" fillcolor=lightblue]
	140579476042672 -> 140583302298160
	140583302298160 [label=AccumulateGrad]
	140583302297776 -> 140579476044272
	140579476044592 [label="
 (1, 7)" fillcolor=darkolivegreen3]
	140583302297872 -> 140579476044592
	140579476044592 -> 140579476044272 [style=dotted]
}
